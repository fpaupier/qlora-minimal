{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e64aabb0-25ef-455f-9494-b6f4ca3ecfc9",
   "metadata": {},
   "source": [
    "1. Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATASET_PATH = './data/english_embeddings.json'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T07:56:38.273621Z",
     "start_time": "2024-01-02T07:56:38.271222Z"
    }
   },
   "id": "119b6f771530d101",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe883fe8-868c-4cc8-92e5-ed9889143ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T07:56:39.842037Z",
     "start_time": "2024-01-02T07:56:39.059724Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "with open(DATASET_PATH) as f:\n",
    "    data = json.load(f)\n",
    "    dataset = Dataset.from_list(data)\n",
    "    dataset_dict = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aab5773-415c-4c90-904a-f5c0a755abfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T07:56:39.845010Z",
     "start_time": "2024-01-02T07:56:39.840345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 221\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 56\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b666c7-108b-4a64-aaec-64dfb1b10078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T07:56:40.208963Z",
     "start_time": "2024-01-02T07:56:40.200040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AJP-3\n",
      "3\n",
      "3-26\n",
      "Edition C Version 1 + UK national elements (Change 1)\n",
      "h. Joint collection management board. J2 chairs the joint collection\n",
      "management board to coordinate collection activities between\n",
      "components, contributing nations, and complementary national agency\n",
      "activity. The overall purpose of the joint collection management board\n",
      "is to review, validate, de-conflict and prioritize all joint intelligence,\n",
      "surveillance and reconnaissance (JISR) collection requirements and\n",
      "assigned capabilities. The joint collection management board seeks to\n",
      "prioritize, coordinate and synchronize the JISR activity between the joint\n",
      "level and the subordinate formations (land, maritime, air, and special\n",
      "operations forces components). At the joint level, subordinate formation\n",
      "component collection management elements participate in the joint\n",
      "collection management board. The board should include, but is not\n",
      "limited to, representation from targeting, current operations, current\n",
      "plans, future plans, electronic warfare, imagery intelligence, signals\n",
      "intelligence, human intelligence, psychological operations, information\n",
      "operations, engineers and CIMIC amongst others. At the joint level, key\n",
      "intelligence requirements management and collection management\n",
      "elements inside the intelligence staff and all supporting/supported\n",
      "components should attend.\n",
      "UK 3.4. Joint Fires and Effects Working Group. The Joint Fires and\n",
      "Effects Working Group (JFEWG) takes the output of the Joint Targeting\n",
      "Working Group, Information Activities Coordination Board and any other\n",
      "targeting working groups and ensure optimal effect capability selection\n",
      "and coordination to achieve the commander's objectives. Targeting staff\n",
      "will start initial coordination of effect integration and synchronisation. The\n",
      "JFEWG represents the final stage of target development prior to submission\n",
      "to the Joint Targeting Coordination Board.\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict[\"train\"][1][\"text\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c851ab41-4a7b-4df1-8140-48623daeae99",
   "metadata": {},
   "source": [
    "2. Load and prepare model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ef7f26-f87b-4c54-924f-c9661bc1bf2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T07:56:58.803641Z",
     "start_time": "2024-01-02T07:56:44.931156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c97154be96bf47b1a448bbdfb7e3f247"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "108fe0a3847e4c6eaabd0a4d7f11e4fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10fa14f9cbb24686a6a05a466c2253e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1a7973764cc48cb8496c4a281fd4446"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load 4-bit quantized model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Load (slow) Tokenizer, fast tokenizer sometimes ignores added tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T07:57:45.035935Z",
     "start_time": "2024-01-02T07:57:44.993715Z"
    }
   },
   "id": "dcb9b08f32688d9f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T07:57:51.435889Z",
     "start_time": "2024-01-02T07:57:51.428271Z"
    }
   },
   "id": "ccbc3b8d9da78965",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948e0d32-60ee-4e0e-9cf5-f17970e4e110",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T07:59:36.394262Z",
     "start_time": "2024-01-02T07:59:35.846060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 283115520 || all params: 4035186688 || trainable%: 7.016169062064471\n"
     ]
    }
   ],
   "source": [
    "# Add LoRA adapters to model\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=\n",
    "    [\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"lm_head\", \"embed_tokens\"],  # needed because we added new tokens to tokenizer/model\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7211c68-07a3-4d24-a7af-a3691063a758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T07:59:47.994266Z",
     "start_time": "2024-01-02T07:59:47.948588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): PeftModelForCausalLM(\n      (base_model): LoraModel(\n        (model): MistralForCausalLM(\n          (model): MistralModel(\n            (embed_tokens): ModulesToSaveWrapper(\n              (original_module): Embedding(32000, 4096)\n              (modules_to_save): ModuleDict(\n                (default): Embedding(32000, 4096)\n              )\n            )\n            (layers): ModuleList(\n              (0-31): 32 x MistralDecoderLayer(\n                (self_attn): MistralAttention(\n                  (q_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (v_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (rotary_emb): MistralRotaryEmbedding()\n                )\n                (mlp): MistralMLP(\n                  (gate_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=14336, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (up_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=4096, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=14336, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (down_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=14336, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=4096, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (act_fn): SiLU()\n                )\n                (input_layernorm): MistralRMSNorm()\n                (post_attention_layernorm): MistralRMSNorm()\n              )\n            )\n            (norm): MistralRMSNorm()\n          )\n          (lm_head): ModulesToSaveWrapper(\n            (original_module): Linear(in_features=4096, out_features=32000, bias=False)\n            (modules_to_save): ModuleDict(\n              (default): Linear(in_features=4096, out_features=32000, bias=False)\n            )\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9913bc18-8a26-4a1b-8abc-3bc8e672f191",
   "metadata": {},
   "source": [
    "3. Prepare data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a941dc-9e9e-4bbd-9c2a-a54f2fd72071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T08:01:36.893947Z",
     "start_time": "2024-01-02T08:01:35.197307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=10):   0%|          | 0/221 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09559f3871c245e98d5a0e376a9fba6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map (num_proc=10):   0%|          | 0/56 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6dbac046de24e66b32654783b65b9ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import os\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "def tokenize(element):\n",
    "    return tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "\n",
    "dataset_tokenized = dataset_dict.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    num_proc=os.cpu_count(),  # multithreaded\n",
    "    remove_columns=[\"text\"]  # don't need this anymore, we have tokens from here on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c427e534-2214-4bc6-8c73-4a81c4984db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T08:01:38.301935Z",
     "start_time": "2024-01-02T08:01:38.265821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 221\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 56\n    })\n})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaae4749-0fd9-4db1-a8b7-33ad164348b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T08:03:23.577124Z",
     "start_time": "2024-01-02T08:03:23.533401Z"
    }
   },
   "outputs": [],
   "source": [
    "# define collate function - transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to single batch dictionary { input_ids: [..], labels: [..], attention_mask: [..] }\n",
    "def collate(elements):\n",
    "    tokenlist = [e[\"input_ids\"] for e in elements]\n",
    "    tokens_maxlen = max([len(t) for t in tokenlist])\n",
    "\n",
    "    input_ids, labels, attention_masks = [], [], []\n",
    "    for tokens in tokenlist:\n",
    "        pad_len = tokens_maxlen - len(tokens)\n",
    "\n",
    "        # pad input_ids with pad_token, labels with ignore_index (-100) and set attention_mask 1 where content otherwise 0\n",
    "        input_ids.append(tokens + [tokenizer.pad_token_id] * pad_len)\n",
    "        labels.append(tokens + [-100] * pad_len)\n",
    "        attention_masks.append([1] * len(tokens) + [0] * pad_len)\n",
    "\n",
    "    batch = {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"labels\": torch.tensor(labels),\n",
    "        \"attention_mask\": torch.tensor(attention_masks)\n",
    "    }\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27287f0e-56f0-458f-8c2e-9124a9739d48",
   "metadata": {},
   "source": [
    " Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e36b9ad9-d0c0-4dc7-a4c8-03765891dac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T08:04:32.165184Z",
     "start_time": "2024-01-02T08:04:32.121007Z"
    }
   },
   "outputs": [],
   "source": [
    "bs = 1  # batch size\n",
    "ga_steps = 1  # gradient acc. steps\n",
    "epochs = 5\n",
    "steps_per_epoch = len(dataset_tokenized[\"train\"]) // (bs * ga_steps)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    eval_steps=steps_per_epoch,  # eval and save once per epoch  \t\n",
    "    save_steps=steps_per_epoch,\n",
    "    gradient_accumulation_steps=ga_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=2e-4,\n",
    "    group_by_length=True,\n",
    "    fp16=True,\n",
    "    ddp_find_unused_parameters=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d8b96-bcfe-490d-8462-dfb44d575432",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-02T08:04:37.830805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpaupier/projects/qlora-minimal/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1105 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fpaupier/projects/qlora-minimal/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/fpaupier/projects/qlora-minimal/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/fpaupier/projects/qlora-minimal/.venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/fpaupier/projects/qlora-minimal/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collate,\n",
    "    train_dataset=dataset_tokenized[\"train\"],\n",
    "    eval_dataset=dataset_tokenized[\"test\"],\n",
    "    args=args,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1996acf7f6d84ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
